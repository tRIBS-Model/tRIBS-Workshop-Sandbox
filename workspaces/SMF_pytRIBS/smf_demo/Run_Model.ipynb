{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab94e641-bca6-47c4-b55d-168c816297d4",
   "metadata": {},
   "source": [
    "# tRIBS-Sandbox: Run Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c13cda9-db1e-4e6f-8155-5872082f63e3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The goal for this notebook is to first run the model we made then use pytRIBS to load in our model outputs and make some plots from the model outputs. The plots shown below are just examples and each output file has multiple variables that can be plotted. Addtion detail on the available model outputs is located [Here](https://tribshms.readthedocs.io/en/latest/man/Output.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c70ee-ef6c-466b-96ac-7a29e06b9950",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd1bcfa-0cbe-4026-95e3-f56e28b7123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note you can install pytRIBS via pip; see: https://pypi.org/project/pytRIBS/\n",
    "from pytRIBS.classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3980742-628a-429a-9ad5-38e5e901df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have installed pytRIBS, the following libraries should already be in your environment\n",
    "import os, sys, shutil\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from shapely.ops import unary_union\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa5de54",
   "metadata": {},
   "source": [
    "### Run The Model\n",
    "In our previous notebook we got everything organized to run the model. Typically tRIBS is ran from the command line but in this codespace we setup and direct path to the tRIBS executeable we can access from within this notebook. So lets run the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71182ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Define File Names\n",
    "input_filename = 'SMF.in'  \n",
    "log_filename   = 'simulation.log'\n",
    "\n",
    "# Pre-run check\n",
    "# Check if the input file actually exists before trying to run.\n",
    "if not os.path.exists(input_filename):\n",
    "    print(f\"ERROR: Could not find input file: '{input_filename}'\")\n",
    "    print(\"Please check your spelling or ensure the previous pytRIBS step ran correctly.\")\n",
    "else:\n",
    "    print(f\"Found input file: {input_filename}\")\n",
    "    print(f\"Starting tRIBS simulation...\")\n",
    "    print(f\"Runtime output is being redirected to: {log_filename}\")\n",
    "\n",
    "    # Execute model\n",
    "    # We use the 'time' module to track how long the simulation takes.\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Run tRIBS! \n",
    "    # syntax: !tRIBS <input_file> > <log_file> 2>&1\n",
    "    exit_code = os.system(f\"tRIBS {input_filename} > {log_filename} 2>&1\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = (end_time - start_time) / 60\n",
    "\n",
    "    # Post-run report\n",
    "    if exit_code == 0:\n",
    "        print(f\"\\nSUCCESS: Simulation completed in {duration:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb2c7e2-1535-4a12-8106-e21f254ddcea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Results Class: Merge and Visualize Results\n",
    "The Results class simplifies working with tRIBS outputs by offering post-processing methods that handle everything from file management to basic model output analysis. tRIBS generates a large amount of data with fine spatial and temporal resolutions, including time series of streamflow and spatially averaged state and flux variables. Additionally, the model produces Voronoi diagrams that can be used with both dynamic snapshots (captured at specific times) and integrated outputs (aggregated over the entire model run). The Results class helps manage these outputs, providing users with tools to merge parallel results and perform further analysis using commonly utilized data libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976f8029-a8f0-4279-887d-b5b41a0a6c4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "name ='SMF'\n",
    "epsg = 26912\n",
    "proj = Project(os.getcwd(),name,epsg) \n",
    "# With this command below pytRIBS will read the input file to ge tthe filepaths of all output locations\n",
    "results = Results('SMF.in',meta=proj.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6a25df-ccdc-4795-b0c8-b4e37333e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = results.voronoi.merge(results.int_spatial_vars,on='ID')\n",
    "results.get_mrf_results()\n",
    "results.get_element_results()\n",
    "\n",
    "strmflw_sim_raw = results.get_qout_results()\n",
    "mrf = results.mrf['mrf']\n",
    "mrf.set_index('Time',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7556f80e",
   "metadata": {},
   "source": [
    "### Visualize Results\n",
    "First lets start with plotting the tRIBS outlet streamflow timeseries and compare it to the observations. Our ouputs and obervational data are not in the same time intervals so we need to do some preprocessing first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61583b7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Time'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/pytRIBS-env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# PREPARE SIMULATED DATA TIMESERIES\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# All we need to do is convert our dataframe into having a datetime index\u001b[39;00m\n\u001b[32m     22\u001b[39m strmflw_sim = strmflw_sim_raw\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m strmflw_sim[\u001b[33m'\u001b[39m\u001b[33mTime\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(\u001b[43mstrmflw_sim\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m     24\u001b[39m strmflw_sim.set_index(\u001b[33m'\u001b[39m\u001b[33mTime\u001b[39m\u001b[33m'\u001b[39m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# RESAMPLE AND ALIGN DATA\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# tRIBS output is every 3.75 mins. Observed is the raw reports.\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# We resample both to a common frequency. Let's use 5 minute averages ('5T') averages. \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/pytRIBS-env/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/pytRIBS-env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Time'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# LOAD AND ORGANIZE OBSERVED DATA\n",
    "# Load data from Excel file\n",
    "obs_filepath = '../smf_init_data/met/SMF_Observations_1993-2025.xlsx'\n",
    "obs_df = pd.read_excel(obs_filepath, sheet_name='Discharge', skiprows=6)\n",
    "\n",
    "# Organize observation so that they are datetime dataframe\n",
    "obs_df['datetime'] = pd.to_datetime(obs_df['Date'].astype(str) + ' ' + obs_df['Time'].astype(str))\n",
    "\n",
    "# Set the datetime as the index \n",
    "obs_df.set_index('datetime', inplace=True)\n",
    "\n",
    "# Convert CFS to CMS (m^3/s) to match tRIBS output. \n",
    "obs_df['Observed_CMS'] = obs_df['cfs'] * 0.0283168\n",
    "\n",
    "\n",
    "# PREPARE SIMULATED DATA TIMESERIES\n",
    "# All we need to do is convert our dataframe into having a datetime index\n",
    "strmflw_sim = strmflw_sim_raw\n",
    "strmflw_sim['Time'] = pd.to_datetime(strmflw_sim['Time'])\n",
    "strmflw_sim.set_index('Time', inplace=True)\n",
    "\n",
    "\n",
    "# RESAMPLE AND ALIGN DATA\n",
    "# tRIBS output is every 3.75 mins. Observed is the raw reports.\n",
    "# We resample both to a common frequency. Let's use 5 minute averages ('5T') averages. \n",
    "obs_resampled = obs_df['Observed_CMS'].resample('5T').mean()\n",
    "sim_resampled = strmflw_sim['Qstrm_m3s'].resample('5T').mean()\n",
    "\n",
    "# Combine into a single dataframe and drop rows where we don't have both data points.\n",
    "compare_df = pd.DataFrame({\n",
    "    'Observed': obs_resampled,\n",
    "    'Simulated': sim_resampled\n",
    "}).dropna()\n",
    "\n",
    "# Define the start and end of the storm event you want to focus on. so we can clip the dataframe\n",
    "event_start = '2014-08-12 16:00'\n",
    "event_end   = '2014-08-12 23:00'\n",
    "event_df = compare_df.loc[event_start:event_end]\n",
    "\n",
    "\n",
    "# PLOTTING THE HYDROGRAPHS\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot Simulated as a solid blue line\n",
    "ax.plot(event_df.index, event_df['Simulated'], \n",
    "        label='Simulated (tRIBS)', color='#1f77b4', linewidth=2)\n",
    "# Plot Observed as black dots/dashed line\n",
    "ax.plot(event_df.index, event_df['Observed'], \n",
    "        label='Observed (Gauge)', color='black', marker='o', markersize=4, linestyle='--', linewidth=1)\n",
    "\n",
    "# Formatting the plot\n",
    "ax.set_title('Simulated vs. Observed Streamflow at Watershed Outlet', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Streamflow ($m^3/s$)', fontsize=12)\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "\n",
    "# Format the x-axis \n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, linestyle=':', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2cf9aa",
   "metadata": {},
   "source": [
    "Now that we have orgnaized and plotted our streamflow data we can look at some preformance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8407a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we are using the clipped storm event dataframe!\n",
    "obs = event_df['Observed']\n",
    "sim = event_df['Simulated']\n",
    "\n",
    "# =========================================================\n",
    "# 1. PHYSICAL EVENT METRICS (Peaks, Timing, Volumes)\n",
    "# =========================================================\n",
    "# Peak Discharge (m^3/s)\n",
    "obs_peak = obs.max()\n",
    "sim_peak = sim.max()\n",
    "\n",
    "# Time to Peak\n",
    "obs_tpeak = obs.idxmax()\n",
    "sim_tpeak = sim.idxmax()\n",
    "\n",
    "# Total Volume (m^3)\n",
    "# Flow is in m^3/s. Our dataframe time interval is whatever we set our resampling interval to earlier.\n",
    "# Lets calculate the time interval from the datafram directly to compute the flow volume.\n",
    "dt_seconds = (event_df.index[1] - event_df.index[0]).total_seconds()\n",
    "obs_vol_m3 = obs.sum() * dt_seconds\n",
    "sim_vol_m3 = sim.sum() * dt_seconds\n",
    "\n",
    "# Volume Error (%)\n",
    "vol_error_pct = ((sim_vol_m3 - obs_vol_m3) / obs_vol_m3) * 100\n",
    "\n",
    "# Statistical Goodness-of-Fit Metrics\n",
    "# Root Mean Square Error (RMSE)\n",
    "rmse = np.sqrt(np.mean((sim - obs)**2))\n",
    "\n",
    "# Nash-Sutcliffe Efficiency (NSE)\n",
    "# NSE = 1 means perfect match. NSE < 0 means the mean of observed is a better predictor than the model.\n",
    "nse = 1 - (np.sum((sim - obs)**2) / np.sum((obs - obs.mean())**2))\n",
    "\n",
    "# Percent Bias (PBIAS)\n",
    "# Positive values indicate overestimation bias, negative indicates underestimation bias.\n",
    "pbias = 100 * (np.sum(sim - obs) / np.sum(obs))\n",
    "\n",
    "# Print a Simple Report\n",
    "print(\"--- HYDROLOGICAL EVENT METRICS ---\")\n",
    "print(f\"Observed Peak Flow: {obs_peak:.2f} m^3/s  (at {obs_tpeak.strftime('%m-%d %H:%M')})\")\n",
    "print(f\"Simulated Peak Flow:{sim_peak:.2f} m^3/s  (at {sim_tpeak.strftime('%m-%d %H:%M')})\")\n",
    "print(f\"Peak Timing Error:  {(sim_tpeak - obs_tpeak).total_seconds() / 3600:.1f} hours\\n\")\n",
    "\n",
    "print(f\"Observed Volume:    {obs_vol_m3:,.0f} m^3\")\n",
    "print(f\"Simulated Volume:   {sim_vol_m3:,.0f} m^3\")\n",
    "print(f\"Volume Error:       {vol_error_pct:+.1f}%\\n\")\n",
    "\n",
    "print(\"--- STATISTICAL PERFORMANCE ---\")\n",
    "print(f\"RMSE:               {rmse:.2f} m^3/s\")\n",
    "print(f\"NSE:                {nse:.3f}\")\n",
    "print(f\"Percent Bias:       {pbias:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf8da7d",
   "metadata": {},
   "source": [
    "tRIBS has many model outputs. One of those is spatial outputs. For this sandbox environment th emodle output the integrated spatial output file which has outputs like time invariant watershed properties but also cumulative outputs of flux variable like evapotranspiration.\n",
    "\n",
    "First spatial plot we will make is the voronoi polygon elevation map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Left PLOT: Elevation and Mesh Structure ---\n",
    "gdf.plot(ax=ax1, column='Z', cmap='terrain', \n",
    "         edgecolor='black', linewidth=0.2,\n",
    "         legend=True, legend_kwds={'label': 'Elevation (m)', 'shrink': 0.8})\n",
    "\n",
    "ax1.set_title('tRIBS Mesh & Elevation', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Longitude', fontsize=12)\n",
    "ax1.set_ylabel('Latitude', fontsize=12)\n",
    "ax1.grid(True, linestyle=':', alpha=0.5)\n",
    "\n",
    "# rightPLOT: Polygon ID\n",
    "gdf.plot(ax=ax2, column='ID', cmap='viridis', \n",
    "         edgecolor='none', \n",
    "         legend=True, legend_kwds={'label': 'Polygon ID (Routing Order)', 'shrink': 0.8})\n",
    "\n",
    "ax2.set_title('Computational Routing Order (Polygon IDs)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Longitude', fontsize=12)\n",
    "ax2.set_yticklabels([]) \n",
    "ax2.grid(True, linestyle=':', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b03f42",
   "metadata": {},
   "source": [
    "Next we can plot the cumulative ET for the entire 480 hour simulaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a3cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Left PLOT: ET\n",
    "gdf.plot(ax=ax1, column='cET', cmap='YlOrBr', legend=True,\n",
    "         edgecolor='none', \n",
    "         legend_kwds={'label': 'Cumulative ET (mm)', 'orientation': 'vertical'})\n",
    "\n",
    "ax1.set_title('Spatial Distribution of Evapotranspiration', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Longitude', fontsize=12)\n",
    "ax1.set_ylabel('Latitude', fontsize=12) \n",
    "ax1.grid(True, linestyle=':', alpha=0.5)\n",
    "\n",
    "# rightPLOT: Depth to Bedrock\n",
    "gdf.plot(ax=ax2, column='Bedrock_Depth_mm', cmap='gist_earth', \n",
    "         edgecolor='none', \n",
    "         legend=True, legend_kwds={'label': 'Depth to Bedrock (mm)', 'shrink': 0.8})\n",
    "\n",
    "ax2.set_title('Spatial Distribution of Bedrock Depth', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Longitude', fontsize=12)\n",
    "ax2.set_yticklabels([]) \n",
    "ax2.grid(True, linestyle=':', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf228411",
   "metadata": {},
   "source": [
    "Interestingly the model has some pretty large differences in cumulative ET. The plot of depth to bedrock was added as one way of getting to an explanation. Since the soils are so shallow on the mountainous slopes the vegetation in those areas has full access to any soil water available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7d0999",
   "metadata": {},
   "source": [
    "Another coomonly used model output is the mean response file (`*.mrf`). This output is a timeseries of many of the model's important variables. In the plot below we include the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b81446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Bottom AXIS: Depth to Groundwater Table \n",
    "ax1.plot(mrf.index, mrf['MDGW'], color='#2ca02c', linewidth=2, label='Basin-Avg Groundwater Depth')\n",
    "\n",
    "ax1.set_xlabel('Date', fontsize=12)\n",
    "ax1.set_ylabel('Depth to Groundwater Table (mm)', fontsize=12, color='#2ca02c')\n",
    "ax1.tick_params(axis='y', labelcolor='#2ca02c')\n",
    "\n",
    "# Lets invert the Y-axis so we can see the depth increase as the watertable is drawn down\n",
    "ax1.invert_yaxis() \n",
    "\n",
    "# Top AXIS: Rainfall Hyetograph\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax2.bar(mrf.index, mrf['MAP'], width=0.02, color='#1f77b4', alpha=0.6, label='Basin-Avg Rainfall')\n",
    "\n",
    "ax2.set_ylabel('Rainfall (mm/hr)', fontsize=12, color='#1f77b4')\n",
    "ax2.tick_params(axis='y', labelcolor='#1f77b4')\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "# Set limits so the rainfall bars only take up the top 30% of the plot\n",
    "max_rain = mrf['MAP'].max()\n",
    "ax2.set_ylim(max_rain * 3, 0) \n",
    "\n",
    "# Formatting\n",
    "ax1.set_title('Basin-Averaged Depth to Groundwater Table', fontsize=14, fontweight='bold')\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "ax1.grid(True, linestyle=':', alpha=0.7)\n",
    "\n",
    "# Combine legends from both axes\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='center right', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14a70b6",
   "metadata": {},
   "source": [
    "Here we plotted to the groundwater depth from mrf file only the lower axis and mean areal precipitation on the top axis. We can see with the shallow depth to bedrock the soil is almost instantly saturated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytRIBS)",
   "language": "python",
   "name": "pytribs-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
